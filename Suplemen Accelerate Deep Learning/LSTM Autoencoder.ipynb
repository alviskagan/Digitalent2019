{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM Autoencoder.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"RkCHseZevztP","colab_type":"text"},"source":["**Reconstruction LSTM Autoencoder**"]},{"cell_type":"code","metadata":{"id":"lZTyWJYduvn9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":360},"outputId":"e03cf5f1-6ada-4de6-a89e-12de70f2da90","executionInfo":{"status":"ok","timestamp":1565745960639,"user_tz":-420,"elapsed":11189,"user":{"displayName":"alviska galuh n","photoUrl":"https://lh4.googleusercontent.com/-SCIzWeHXp_I/AAAAAAAAAAI/AAAAAAAAAAU/dsg-SPKKsxA/s64/photo.jpg","userId":"15388036559215776599"}}},"source":["# lstm autoencoder recreate sequence\n","from numpy import array\n","from keras.models import Sequential\n","from keras.layers import LSTM\n","from keras.layers import Dense\n","from keras.layers import RepeatVector\n","from keras.layers import TimeDistributed\n","from keras.utils import plot_model\n","\n","# define input sequence\n","sequence = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n","\n","# reshape input into [samples, timesteps, features]\n","n_in = len(sequence)\n","sequence = sequence.reshape((1, n_in, 1))\n","\n","# define model\n","model = Sequential()\n","model.add(LSTM(100, activation='relu', input_shape=(n_in,1)))\n","model.add(RepeatVector(n_in))\n","model.add(LSTM(100, activation='relu', return_sequences=True))\n","model.add(TimeDistributed(Dense(1)))\n","model.compile(optimizer='adam', loss='mse')\n","\n","# fit model\n","model.fit(sequence, sequence, epochs=300, verbose=0)\n","plot_model(model, show_shapes=True, to_file='reconstruct_lstm_autoencoder.png')\n","\n","# demonstrate recreation\n","yhat = model.predict(sequence, verbose=0)\n","print(yhat[0,:,0])"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","WARNING: Logging before flag parsing goes to stderr.\n","W0814 01:25:51.437162 139998407567232 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0814 01:25:51.476914 139998407567232 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0814 01:25:51.484309 139998407567232 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0814 01:25:52.119828 139998407567232 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0814 01:25:52.433589 139998407567232 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0814 01:25:53.678186 139998407567232 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","W0814 01:25:53.804639 139998407567232 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["[0.10484007 0.20024277 0.29893196 0.39903706 0.49956563 0.5999912\n"," 0.7001451  0.80012715 0.900236  ]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"a_7j0-KxvwKl","colab_type":"text"},"source":["**Prediction LSTM Autoencoder**"]},{"cell_type":"code","metadata":{"id":"zVK3G3wfuw1T","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"ec2175b8-76b8-4124-ff8a-f2ffd8f15240","executionInfo":{"status":"ok","timestamp":1565746014019,"user_tz":-420,"elapsed":9093,"user":{"displayName":"alviska galuh n","photoUrl":"https://lh4.googleusercontent.com/-SCIzWeHXp_I/AAAAAAAAAAI/AAAAAAAAAAU/dsg-SPKKsxA/s64/photo.jpg","userId":"15388036559215776599"}}},"source":["# define input sequence\n","seq_in = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n","\n","# reshape input into [samples, timesteps, features]\n","n_in = len(seq_in)\n","seq_in = seq_in.reshape((1, n_in, 1))\n","\n","# prepare output sequence\n","seq_out = seq_in[:, 1:, :]\n","n_out = n_in - 1\n","\n","# define model\n","model = Sequential()\n","model.add(LSTM(100, activation='relu', input_shape=(n_in,1)))\n","model.add(RepeatVector(n_out))\n","model.add(LSTM(100, activation='relu', return_sequences=True))\n","model.add(TimeDistributed(Dense(1)))\n","model.compile(optimizer='adam', loss='mse')\n","plot_model(model, show_shapes=True, to_file='predict_lstm_autoencoder.png')\n","\n","# fit model\n","model.fit(seq_in, seq_out, epochs=300, verbose=0)\n","\n","# demonstrate prediction\n","yhat = model.predict(seq_in, verbose=0)\n","print(yhat[0,:,0])"],"execution_count":2,"outputs":[{"output_type":"stream","text":["[0.16613358 0.28874403 0.40254888 0.5093199  0.6104444  0.7070395\n"," 0.80003124 0.89021   ]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pU0hY3zcvStE","colab_type":"code","colab":{}},"source":["#  lstm autoencoder reconstruct and predict sequence\n","from numpy import array\n","from keras.models import Model\n","from keras.layers import Input\n","from keras.layers import LSTM\n","from keras.layers import Dense\n","from keras.layers import RepeatVector\n","from keras.layers import TimeDistributed\n","from keras.utils import plot_model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nnjs9IWFvp3h","colab_type":"text"},"source":["**Composite LSTM Autoencoder**"]},{"cell_type":"code","metadata":{"id":"8mhD1LqPvANP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":289},"outputId":"007f6ca8-31c1-47be-bbdd-43bcf6bf9386","executionInfo":{"status":"ok","timestamp":1565746138139,"user_tz":-420,"elapsed":13321,"user":{"displayName":"alviska galuh n","photoUrl":"https://lh4.googleusercontent.com/-SCIzWeHXp_I/AAAAAAAAAAI/AAAAAAAAAAU/dsg-SPKKsxA/s64/photo.jpg","userId":"15388036559215776599"}}},"source":["# define input sequence\n","seq_in = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n","\n","# reshape input into [samples, timesteps, features]\n","n_in = len(seq_in)\n","seq_in = seq_in.reshape((1, n_in, 1))\n","\n","# prepare output sequence\n","seq_out = seq_in[:, 1:, :]\n","n_out = n_in - 1\n","\n","# define encoder\n","visible = Input(shape=(n_in,1))\n","encoder = LSTM(100, activation='relu')(visible)\n","\n","# define reconstruct decoder\n","decoder1 = RepeatVector(n_in)(encoder)\n","decoder1 = LSTM(100, activation='relu', return_sequences=True)(decoder1)\n","decoder1 = TimeDistributed(Dense(1))(decoder1)\n","\n","# define predict decoder\n","decoder2 = RepeatVector(n_out)(encoder)\n","decoder2 = LSTM(100, activation='relu', return_sequences=True)(decoder2)\n","decoder2 = TimeDistributed(Dense(1))(decoder2)\n","\n","# tie it together\n","model = Model(inputs=visible, outputs=[decoder1, decoder2])\n","model.compile(optimizer='adam', loss='mse')\n","plot_model(model, show_shapes=True, to_file='composite_lstm_autoencoder.png')\n","\n","# fit model\n","model.fit(seq_in, [seq_in,seq_out], epochs=300, verbose=0)\n","\n","# demonstrate prediction\n","yhat = model.predict(seq_in, verbose=0)\n","print(yhat)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[array([[[0.11021672],\n","        [0.20789155],\n","        [0.3045485 ],\n","        [0.40044165],\n","        [0.49661556],\n","        [0.5941415 ],\n","        [0.6941657 ],\n","        [0.7979694 ],\n","        [0.90703845]]], dtype=float32), array([[[0.16879326],\n","        [0.29085186],\n","        [0.4024964 ],\n","        [0.5075912 ],\n","        [0.60796845],\n","        [0.7050089 ],\n","        [0.79981226],\n","        [0.8933235 ]]], dtype=float32)]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UzgD2DnSvmMU","colab_type":"text"},"source":["**Keep Standalone LSTM Encoder**"]},{"cell_type":"code","metadata":{"id":"iVlAu7_ovOTj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":459},"outputId":"f438f179-f83d-40ec-ee28-e85f813fcc56","executionInfo":{"status":"ok","timestamp":1565746152650,"user_tz":-420,"elapsed":9934,"user":{"displayName":"alviska galuh n","photoUrl":"https://lh4.googleusercontent.com/-SCIzWeHXp_I/AAAAAAAAAAI/AAAAAAAAAAU/dsg-SPKKsxA/s64/photo.jpg","userId":"15388036559215776599"}}},"source":["# define input sequence\n","sequence = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n","# reshape input into [samples, timesteps, features]\n","n_in = len(sequence)\n","sequence = sequence.reshape((1, n_in, 1))\n","# define model\n","model = Sequential()\n","model.add(LSTM(100, activation='relu', input_shape=(n_in,1)))\n","model.add(RepeatVector(n_in))\n","model.add(LSTM(100, activation='relu', return_sequences=True))\n","model.add(TimeDistributed(Dense(1)))\n","model.compile(optimizer='adam', loss='mse')\n","# fit model\n","model.fit(sequence, sequence, epochs=300, verbose=0)\n","# connect the encoder LSTM as the output layer\n","model = Model(inputs=model.inputs, outputs=model.layers[0].output)\n","plot_model(model, show_shapes=True, to_file='lstm_encoder.png')\n","# get the feature vector for the input sequence\n","yhat = model.predict(sequence)\n","print(yhat.shape)\n","print(yhat)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["(1, 100)\n","[[0.00000000e+00 8.40858147e-02 1.02115028e-01 0.00000000e+00\n","  4.29800265e-02 2.34062616e-02 2.81083435e-02 5.50449751e-02\n","  6.30786642e-02 0.00000000e+00 6.31890222e-02 3.07526104e-02\n","  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n","  1.03702806e-02 9.41602662e-02 0.00000000e+00 0.00000000e+00\n","  0.00000000e+00 0.00000000e+00 8.45623389e-02 9.90664214e-02\n","  7.69042224e-02 0.00000000e+00 1.33752739e-02 8.61792490e-02\n","  1.01291709e-01 0.00000000e+00 0.00000000e+00 8.61476734e-02\n","  0.00000000e+00 2.44012428e-03 0.00000000e+00 0.00000000e+00\n","  0.00000000e+00 8.46719816e-02 5.65234944e-03 7.17138946e-02\n","  6.84074983e-02 1.07211845e-05 3.32521312e-02 0.00000000e+00\n","  0.00000000e+00 0.00000000e+00 6.15448505e-02 6.77432269e-02\n","  1.12942457e-01 2.02066302e-02 0.00000000e+00 0.00000000e+00\n","  8.07264447e-02 9.78117809e-02 2.29334123e-02 2.38395780e-02\n","  1.03342935e-01 0.00000000e+00 4.24865782e-02 0.00000000e+00\n","  5.61717674e-02 2.80754436e-02 9.73819196e-02 0.00000000e+00\n","  0.00000000e+00 1.01369701e-01 8.88726953e-03 0.00000000e+00\n","  1.59381442e-02 0.00000000e+00 6.95086718e-02 0.00000000e+00\n","  0.00000000e+00 3.91698442e-02 0.00000000e+00 3.29149999e-02\n","  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n","  0.00000000e+00 0.00000000e+00 7.62954950e-02 0.00000000e+00\n","  7.70662203e-02 1.09075300e-01 0.00000000e+00 1.14342645e-01\n","  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.41876822e-02\n","  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n","  0.00000000e+00 8.72548744e-02 1.08218700e-01 5.00156507e-02]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8dF8o3Clvh15","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}